{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62a5138",
   "metadata": {},
   "source": [
    "# Point Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Folder names\n",
    "folder_path = \"small_dataset/train\"  \n",
    "file_name = \"f_0.json\"        \n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215569b1",
   "metadata": {},
   "source": [
    "Peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637d50dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula\n",
      "formula_depth\n",
      "points\n",
      "n_vars\n",
      "n_consts\n",
      "n_points\n",
      "var_bound_dict\n",
      "const_value_dict\n",
      "meta_list\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{file_name} doesn't exist at {folder_path}.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Couldn't decode {file_name}.\")\n",
    "\n",
    "for key, value in data.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b27b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_0': [-2.79008, -1.43651, -1.39172, 0.24824, 3.63193, -1.02878, -3.51268, 0.03997, -4.64088, -1.57417, 0.13335, 0.17542, 3.20014, 3.0211, -2.15762, -1.9855, 4.81394, -1.10188, -3.58234, 1.55946, -2.54935, 1.04478, 3.21744, -3.25277, -0.4874, -1.18187, 4.95992, 2.10747, -4.20734, -2.70941, -3.44772, -4.85176, -1.84627, -1.79998, -2.6889, 0.54344, -2.81412, 4.43828, 2.33473, -3.79659, -2.3523, 4.84024, -2.96959, -3.87053, -2.67405, 2.13423, 0.13502, -4.34976, -1.37471, -4.10443, -2.09117, -3.2892, -2.79626, 2.79426, 2.82545, 2.32883, 1.91456, -2.57005, -0.5899, -0.40422, 0.34098, 3.55448, 3.88414, -2.8427, -0.69123, -3.50898, 1.47471, 0.70889, 3.49245, 0.20351, 2.78136, -1.81472, 1.95154, -4.64605, -3.50091, -0.5112, 3.90975, 3.83586, 0.96975, -3.71553, 1.82143, -3.2294, -1.49144, -1.84215, 3.87718, 1.89716, -4.27646, 3.45696, -0.68395, 2.54025, 2.79105, 4.97805, -1.52602, 3.62118, -2.13553, 4.98068, -0.87596, 1.61298, 4.99432, -2.97843], 'var_1': [1.23101, 4.99008, 4.44332, -2.80567, -4.01179, -0.73612, 2.65338, 2.92275, 1.04908, 1.15769, -3.78815, -0.56448, 0.74989, 1.83006, -4.07685, 1.91262, 4.427, 2.88422, 1.23448, -4.04655, 2.92468, 1.6573, 0.46726, 3.04141, 1.70319, -0.29049, -2.65644, 0.05933, -3.46396, -4.40029, -2.65628, -1.3515, 1.47093, -0.00498, 2.38474, 2.39259, 2.07677, 0.47953, 1.64698, 4.74239, 2.07602, 2.40869, -2.11347, -0.22244, -0.63653, -1.41104, -0.44487, 0.96848, 1.24463, 3.38442, 1.61505, 3.70423, 1.56227, -1.5241, 1.29663, 2.30483, 1.84468, 3.51294, 4.06664, -1.64065, -4.19919, 1.57952, -3.89914, 3.835, 3.2193, 2.10721, 4.28667, 3.84101, 4.19202, 2.38992, -1.29509, -4.52511, -4.35436, 2.92183, -3.06449, -1.87507, 0.87204, -3.6881, 4.82185, 3.15783, 0.83952, 4.08987, -0.06376, 3.93496, 3.24335, -4.8337, 2.96148, 2.81155, -1.80572, -0.07374, -3.59998, 1.65189, 1.72753, 4.79682, 2.23003, -0.48583, -3.20571, 2.88117, -1.42083, 4.43825], 'var_2': [-2.25072, -3.03545, 1.20933, 4.1356, -3.59812, -4.60251, 4.71545, -3.65898, 1.06284, -3.03963, -3.33861, -3.44461, 2.11222, 2.61192, -3.8118, -3.62642, 4.30206, 0.89286, 2.80203, -4.19825, -4.45426, -1.04361, 0.56589, -1.31317, 2.13749, 1.7284, -0.5393, -4.22764, 0.97047, -2.56715, -1.13147, -4.89665, 0.1978, 1.97428, 0.77103, 2.49323, 5.00671, 1.33296, -2.74807, 0.735, -2.56588, -1.711, -1.45604, 0.15823, 0.21349, 1.68354, -0.6084, -3.12458, -0.0967, 2.95444, 2.01413, -3.85156, 4.52002, -1.99025, 0.84468, -4.64498, 4.11393, 1.8084, -2.24341, 1.84908, -2.0538, -2.42241, -0.54433, 0.98053, -2.91173, 2.43821, 0.80562, -4.9532, 0.51399, -0.7872, 1.68877, 4.02645, -2.33953, 1.70043, -3.44886, -4.14377, 4.29138, 3.64793, 0.0401, -3.61518, -2.35786, 0.67641, 1.51657, 1.93891, 2.47306, -2.87433, -2.02626, -4.89856, -4.26307, -1.906, -3.15319, -0.084, 3.49988, 2.24713, 2.55848, 1.00587, 1.99668, -3.20733, 0.52969, 0.72002], 'target': [8.83213, 1000000.01962, -83149.46566, 183.28609, -24623.24181, 5.66045, 10.69599, 211.93865, 5.54178, 7.35384, 3857.25162, 3.58247, 5.51044, 23.313, 17876.98023, 26.63496, 110742.02319, -245.394, -1.42164, 8042.42841, 372.50016, -51.78898, 3.72782, 364.48935, 5.87409, -1.69288, 127.0085, 1.89776, 1158.07428, 55560.45862, 131.07503, 13.76693, 3.63158, -3.62779, 24.99926, 46.86327, 16.25031, 4.97672, -7.23973, 1000000.02949, 32.90957, 54.02126, 33.17873, 3.34915, 2.67692, 9.82365, -2.23413, 8.14795, 2.05087, 125.05429, -23.31184, 4570.50766, 4.46216, -1.39028, 7.70854, 29.52739, 25.12372, -385.05655, 9463.81837, 3.49568, 9096.28517, 1.2109, 6053.96732, 2436.41594, 575.27706, 2.18503, 16327.40669, 6528.19337, 27735.95762, -20.34707, 9.0649, 76952.05457, -28056.38589, 193.60638, 569.17746, 22.20415, 7.58246, 4571.45493, 1749.999, 762.55443, -2.11144, 9389.88781, -9.5185, -20250.49088, 936.12451, -35009.93803, 377.95491, 51.46854, 21.23147, -1.13412, -1718.63293, 16.03416, 7.76994, 999999.99803, -26.44775, 5.20704, 42.34638, 73.73413, 12.29975, 41425.48377]}\n"
     ]
    }
   ],
   "source": [
    "print(data['points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc1329",
   "metadata": {},
   "source": [
    "Create a pytorch tensor with batch size num_files containing each equation's set of points. Each set of input points is represented by a 100 x 4 matrix [x_0 x_1 x_2 y], where x_0 is an array of 100 values and similarly for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30493ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Number of json files to read\n",
    "num_files = 16\n",
    "\n",
    "for i in range(num_files):\n",
    "    folder_path = \"small_dataset/train\"\n",
    "    file_name = f\"f_{i}.json\"\n",
    "\n",
    "    # File path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_name} doesn't exist at {folder_path}.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Couldn't decode {file_name}.\")\n",
    "        \n",
    "    point_data = [data['points']['var_0'], data['points']['var_1'], data['points']['var_2'], data['points']['target']]\n",
    "    \n",
    "    input_data = {\n",
    "        \"pointwise_data\": point_data\n",
    "    }\n",
    "    \n",
    "    if i == 0:\n",
    "        train_points = torch.tensor(input_data['pointwise_data'], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        points = torch.tensor(input_data['pointwise_data'], dtype=torch.float32).unsqueeze(0)\n",
    "        train_points = torch.cat((train_points, points), dim=0)\n",
    "\n",
    "print(train_points.shape) # [batch size, channels, sequence length]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf57ba5",
   "metadata": {},
   "source": [
    "This is the implementation from SymbolicGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16fd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVars = 3 # number of x variables\n",
    "numYs = 1 # number of y variables\n",
    "embeddingSize = 512\n",
    "embeddingSize = 384\n",
    "num_units = embeddingSize\n",
    "\n",
    "# Define the embedding model\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        \n",
    "        self.activation_func = F.relu\n",
    "        self.num_units = embeddingSize\n",
    "\n",
    "        self.conv1 = nn.Conv1d(numVars + numYs, num_units, 1)\n",
    "        self.conv2 = nn.Conv1d(num_units, 2 * num_units, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * num_units, 4 * num_units, 1)\n",
    "        self.fc1 = nn.Linear(4 * num_units, 2 * num_units)\n",
    "        self.fc2 = nn.Linear(2 * num_units, num_units)\n",
    "\n",
    "        self.input_batch_norm = nn.BatchNorm1d(numVars + numYs)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_units)\n",
    "        self.bn2 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn3 = nn.BatchNorm1d(4 * self.num_units)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn5 = nn.BatchNorm1d(self.num_units)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_batch_norm(x)\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        print(x.shape)\n",
    "        x, _ = torch.max(x, dim=2)  \n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7588720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 100])\n",
      "torch.Size([16, 384, 100])\n",
      "torch.Size([16, 768, 100])\n",
      "torch.Size([16, 1536, 100])\n",
      "torch.Size([16, 1536])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([16, 384])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = EmbeddingModel()\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model(train_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322b657",
   "metadata": {},
   "source": [
    "The output is a vector of size 1 x e, where e is the embedding size. In this example, we use e = 512. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0b3a8",
   "metadata": {},
   "source": [
    "# Token Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db456c23",
   "metadata": {},
   "source": [
    "Next is the equation tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0adef960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(exp(reverse(var_0, N), N(N, N)), gaussian(add(var_2, var_1), N(N, N)))mult(gaussian(add(var_1, var_0), N(N, N)), exp(mult(var_2, C_0), N(N, N)))add(sqrt(mult(var_1, var_2), N(N, N)), pow_2(sqrt(var_0, N), N(N, N)))add(mult(sinh(var_1, N), var_2(N, N)), reverse(tan(var_0, N), N(N, N)))log(add(mult(var_1, C_0), mult(var_2, var_0)), N(N(N, N), N(N, N)))mult(cosh(reverse(var_1, N), N(N, N)), reverse(mult(var_0, var_2), N(N, N)))add(sqrt(gaussian(var_0, N), N(N, N)), exp(add(var_1, var_2), N(N, N)))add(sqrt(add(var_2, C_0), N(N, N)), reverse(add(var_1, var_0), N(N, N)))mult(add(sin(var_1, N), reverse(var_2, N)), add(log(var_0, N), log(var_1, N)))mult(add(sinh(var_1, N), add(var_2, var_2)), sqrt(add(var_0, C_0), N(N, N)))sqrt(add(var_2(N, N), add(var_1, var_0)), N(N(N, N), N(N, N)))mult(add(pow_2(var_0, N), var_2(N, N)), exp(sin(var_1, N), N(N, N)))add(add(exp(var_1, N), mult(var_2, C_0)), tan(gaussian(var_0, N), N(N, N)))gaussian(mult(cos(var_0, N), mult(var_2, var_1)), N(N(N, N), N(N, N)))add(mult(mult(var_1, C_0), cos(var_0, N)), add(add(var_2, C_1), C_2(N, N)))add(mult(mult(var_2, var_2), exp(var_0, N)), cos(mult(var_1, C_0), N(N, N)))mult(cosh(mult(var_0, var_1), N(N, N)), gaussian(tanh(var_2, N), N(N, N)))add(add(mult(var_0, var_1), add(var_2, var_1)), reverse(C_0(N, N), N(N, N)))mult(add(var_2(N, N), add(var_1, var_0)), pow_2(gaussian(var_2, N), N(N, N)))mult(log(add(var_2, var_0), N(N, N)), reverse(gaussian(var_1, N), N(N, N)))\n"
     ]
    }
   ],
   "source": [
    "# Number of json files to read\n",
    "num_files = 20\n",
    "\n",
    "equations = \"\"\n",
    "\n",
    "formulas = []\n",
    "\n",
    "for i in range(num_files):\n",
    "    folder_path = \"small_dataset/train\"\n",
    "    file_name = f\"f_{i}.json\"\n",
    "\n",
    "    # Fill path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_name} doesn't exist at {folder_path}.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Couldn't decode {file_name}.\")\n",
    "        \n",
    "    eq = data['formula']\n",
    "    \n",
    "    equations = ''.join([eq,equations])\n",
    "    \n",
    "    formula_data = eq\n",
    "    \n",
    "    formulas.append(formula_data)\n",
    "\n",
    "print(equations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4926ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mult(log(add(var_2, var_0), N(N, N)), reverse(gaussian(var_1, N), N(N, N)))\n"
     ]
    }
   ],
   "source": [
    "print(formulas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd5a8c",
   "metadata": {},
   "source": [
    "Equations is just a big long string containing every equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ad2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '(', ')', ',', '0', '1', '2', ':', '<', '>', 'C', 'N', 'T', '_', '_', 'a', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(equations))+['_','T','<','>',':'])\n",
    "print(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c05356",
   "metadata": {},
   "source": [
    "These dictionaries define the mapping from string to token and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9793a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '(': 1, ')': 2, ',': 3, '0': 4, '1': 5, '2': 6, ':': 7, '<': 8, '>': 9, 'C': 10, 'N': 11, 'T': 12, '_': 14, 'a': 15, 'c': 16, 'd': 17, 'e': 18, 'g': 19, 'h': 20, 'i': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x': 34}\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2bab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '(', 2: ')', 3: ',', 4: '0', 5: '1', 6: '2', 7: ':', 8: '<', 9: '>', 10: 'C', 11: 'N', 12: 'T', 13: '_', 14: '_', 15: 'a', 16: 'c', 17: 'd', 18: 'e', 19: 'g', 20: 'h', 21: 'i', 22: 'l', 23: 'm', 24: 'n', 25: 'o', 26: 'p', 27: 'q', 28: 'r', 29: 's', 30: 't', 31: 'u', 32: 'v', 33: 'w', 34: 'x'}\n"
     ]
    }
   ],
   "source": [
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f47d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dix = [stoi[s] for s in '<'+eq+'>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16afba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 15, 17, 17, 1, 18, 34, 26, 1, 28, 18, 32, 18, 28, 29, 18, 1, 32, 15, 28, 14, 4, 3, 0, 11, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 3, 0, 19, 15, 31, 29, 29, 21, 15, 24, 1, 15, 17, 17, 1, 32, 15, 28, 14, 6, 3, 0, 32, 15, 28, 14, 5, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "print(dix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aff7db",
   "metadata": {},
   "source": [
    "It seems like dix is the tokenized representation of an equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eeb968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', 'a', 'd', 'd', '(', 'e', 'x', 'p', '(', 'r', 'e', 'v', 'e', 'r', 's', 'e', '(', 'v', 'a', 'r', '_', '0', ',', ' ', 'N', ')', ',', ' ', 'N', '(', 'N', ',', ' ', 'N', ')', ')', ',', ' ', 'g', 'a', 'u', 's', 's', 'i', 'a', 'n', '(', 'a', 'd', 'd', '(', 'v', 'a', 'r', '_', '2', ',', ' ', 'v', 'a', 'r', '_', '1', ')', ',', ' ', 'N', '(', 'N', ',', ' ', 'N', ')', ')', ')', '>']\n"
     ]
    }
   ],
   "source": [
    "dummy = [s for s in '<'+eq+'>']\n",
    "print(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830c3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 15, 17, 17, 1, 18, 34, 26, 1, 28, 18, 32, 18, 28, 29, 18, 1, 32, 15, 28, 14, 4, 3, 0, 11, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 3, 0, 19, 15, 31, 29, 29, 21, 15, 24, 1, 15, 17, 17, 1, 32, 15, 28, 14, 6, 3, 0, 32, 15, 28, 14, 5, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 2]\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "inputs = dix[:-1]\n",
    "outputs = dix[1:]\n",
    "\n",
    "print(inputs)\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490d765",
   "metadata": {},
   "source": [
    "In SymbolicGPT, the encoded equations look like this: tensor([23, 25,  5, 50, 13,  5,  5, 16,  6, 25,  5, 50, 13,  5,  5, 15,  6, 25,\n",
    "         5, 50, 13,  5,  5, 14,  6, 25,  5, 50, 13,  5,  5, 13,  6, 25,  5, 50,\n",
    "        13,  6, 25, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
    "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920e2f5",
   "metadata": {},
   "source": [
    "The way they get these equations is as follows: cap the length of the token sequence by the prespecified block size. For example, block size is 64. Before padding, the input length is 39, so the padding size is 25. Thus, the sequence is length 64. Similarly, truncate the sequence down if the length exceeds 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39611981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 17, 17, 1, 18, 34, 26, 1, 28, 18, 32, 18, 28, 29, 18, 1, 32, 15, 28, 14, 4, 3, 0, 11, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 3, 0, 19, 15, 31, 29, 29, 21, 15, 24, 1, 15, 17, 17, 1, 32, 15, 28, 14, 6, 3, 0, 32, 15, 28, 14, 5, 2, 3, 0, 11, 1, 11, 3, 0, 11, 2, 2, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04ee94",
   "metadata": {},
   "source": [
    "It's not clear immediately what vocab_size is, but it appears to be len(chars), where chars is the list of unique characters found across all the equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cae17",
   "metadata": {},
   "source": [
    "Formulas need to be tokenized, embedded, and then concatenated because their number of characters will initially differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91835d4f",
   "metadata": {},
   "source": [
    "The embedding stem takes a padding index as an argument, which is determined by \n",
    "self.paddingToken = '_', self.paddingID = self.stoi[self.paddingToken], where paddingID was assigned to the train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93cb8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "paddingToken = '_'\n",
    "paddingID = stoi[paddingToken]\n",
    "print(paddingID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4725f54",
   "metadata": {},
   "source": [
    "For now, we'll follow their convention and cap token length at 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210c92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 23, 31,  ...,  3,  0, 11],\n",
      "        [ 8, 23, 31,  ..., 14,  6,  3],\n",
      "        [ 8, 15, 17,  ..., 11,  3,  0],\n",
      "        ...,\n",
      "        [ 8, 15, 17,  ...,  0, 11,  1],\n",
      "        [ 8, 23, 31,  ..., 14,  4,  2],\n",
      "        [ 8, 15, 17,  ..., 14,  5,  2]], dtype=torch.int32)\n",
      "torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "formula_data = [eq]\n",
    "max_length = 64\n",
    "    \n",
    "char_data = {\n",
    "    \"char_data\": formula_data\n",
    "}\n",
    "\n",
    "for i in range(len(formulas)):\n",
    "    dix = [stoi[s] for s in '<'+formulas[i]+'>']\n",
    "    inputs = dix[:-1] # dunno why this is needed\n",
    "    \n",
    "    paddingSize = max(max_length-len(inputs),0)\n",
    "    paddingList = [paddingID]*paddingSize\n",
    "    \n",
    "    # Pad or truncate as needed\n",
    "    inputs += paddingList\n",
    "    inputs = inputs[:max_length]\n",
    "    \n",
    "    char_data = {\n",
    "        \"char_data\": inputs\n",
    "    }\n",
    "    \n",
    "    if i == 0:\n",
    "        train_chars = torch.tensor(char_data['char_data'], dtype=torch.int32).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        chars = torch.tensor(char_data['char_data'], dtype=torch.int32).unsqueeze(0)\n",
    "        train_chars = torch.cat((train_chars, chars), dim=0)\n",
    "\n",
    "print(train_chars)\n",
    "print(train_chars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d9df7",
   "metadata": {},
   "source": [
    "Presumably, self.tok_emb(idx) is passing the embedding layer on dix, the sequence of tokens. So it goes \n",
    "add(exp(reverse(var_0, N), N(N, N)) => [8, 15, ... , 2, 2] => [0.01, ... , 0.99]. At the end, the logits should yield tokens, which can then be decoded to an equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3be1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \"\"\"  the full GPT language model, with a context size of block_size \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        vocabSize = 35\n",
    "        blockSize = 64 # use block size 64 for now\n",
    "        drop_out = 0.1\n",
    "\n",
    "        # input embedding stem\n",
    "        self.tok_emb = nn.Embedding(vocabSize, embeddingSize, padding_idx=paddingID) # padding ID = 14    \n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, blockSize, embeddingSize))\n",
    "        self.drop = nn.Dropout(drop_out)        \n",
    "        \n",
    "    def forward(self, idx):\n",
    "        b, t = idx.size()\n",
    "\n",
    "        # forward the GPT model\n",
    "        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector -> b x length x embedding\n",
    "        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector\n",
    "\n",
    "        # summation\n",
    "        input_embedding = token_embeddings + position_embeddings #+ points_embeddings\n",
    "        \n",
    "        return input_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c8f06b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 64, 384])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "gpt_model = GPT()\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = gpt_model(train_chars)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "959acb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.4439e-02,  7.7788e-01,  1.4444e-01,  3.2463e-01,  3.5825e-01,\n",
      "        -2.1916e+00,  3.1082e-01,  3.0723e-01, -1.7287e+00, -1.0041e+00,\n",
      "        -1.2744e+00,  5.5562e-01,  1.2556e+00,  5.1207e-01, -5.4144e-03,\n",
      "         2.8505e-01,  6.2066e-01,  3.9447e-01,  7.5440e-01, -3.3477e-01,\n",
      "        -1.8021e-01, -3.1248e-02, -6.0185e-02, -1.2717e+00,  7.6769e-01,\n",
      "         1.2364e+00, -7.5234e-01, -1.7104e-02,  4.5301e-01, -1.7334e-02,\n",
      "        -1.9353e+00, -1.2685e+00, -8.0235e-01, -6.5134e-01, -3.2802e-01,\n",
      "         1.7287e+00, -4.8262e-01, -1.3007e+00, -9.4437e-01, -1.6297e+00,\n",
      "         9.3883e-01,  1.6431e-01,  1.0406e+00,  1.2632e+00,  1.8008e-02,\n",
      "        -5.3831e-01,  5.7271e-01,  1.3792e+00,  1.0563e+00, -1.1543e+00,\n",
      "        -8.8845e-01, -1.1591e+00, -1.2048e-01,  2.3298e+00,  3.9128e-01,\n",
      "         4.8654e-01, -4.5392e-01,  1.8232e-01,  9.5347e-02,  4.4730e-01,\n",
      "        -9.6029e-01, -5.3801e-01,  5.0961e-01, -4.8260e-01, -5.6868e-02,\n",
      "        -3.5467e-01, -1.1205e+00,  1.1934e-01, -8.8127e-02,  1.0651e+00,\n",
      "        -6.5238e-01,  1.6817e+00, -2.1805e-02,  1.1325e+00, -3.4578e-01,\n",
      "         2.4421e+00,  1.3538e+00,  7.9016e-01, -7.2948e-02,  4.5013e-01,\n",
      "        -5.6575e-01, -1.1079e+00,  1.8865e-01, -3.5611e-01, -2.5792e-01,\n",
      "         1.2764e+00, -1.9049e+00,  8.1304e-01, -1.6035e+00, -1.0426e+00,\n",
      "        -8.7034e-02,  1.8882e+00, -8.1521e-01, -6.8590e-01, -8.4767e-01,\n",
      "        -1.0931e+00,  1.9878e+00, -1.0557e+00, -6.7548e-01,  9.2712e-01,\n",
      "        -4.6030e-01, -3.4440e-01,  1.2861e+00,  4.3467e-01,  1.4276e-01,\n",
      "        -2.4958e+00,  6.2818e-01,  4.3950e-01, -1.0056e+00,  1.6864e-01,\n",
      "        -4.9970e-01, -1.4966e+00,  2.4635e+00,  2.1428e-01, -5.7135e-01,\n",
      "        -1.1949e-01,  6.6576e-01, -1.5453e-01,  2.0850e+00,  1.7877e-01,\n",
      "        -9.7412e-01, -1.0265e+00,  2.9166e-01,  1.0744e-01, -4.0519e-01,\n",
      "         9.1244e-01,  3.9998e-01, -9.3363e-02,  1.1815e+00, -1.0343e+00,\n",
      "         1.8147e+00, -6.4304e-01,  1.0096e-01, -1.5224e+00,  1.3382e+00,\n",
      "         1.1469e+00,  6.9135e-01, -7.1598e-01,  2.0735e+00, -2.3260e+00,\n",
      "         1.0682e+00, -6.7137e-01,  1.6604e-01, -2.2420e-01, -1.5378e+00,\n",
      "         2.2997e-02, -6.1897e-01,  9.5651e-04,  2.2341e-01,  3.0745e-02,\n",
      "        -4.4760e-01,  4.5579e-01, -7.5559e-02,  1.6083e+00, -8.0376e-02,\n",
      "         1.6805e+00,  1.5006e+00,  1.0233e+00, -4.9550e-01,  3.5727e-02,\n",
      "        -1.1399e+00, -1.0211e+00, -2.2188e-02,  4.3185e-01,  9.3918e-01,\n",
      "         2.0176e+00, -1.8024e-01,  6.9713e-01, -1.6117e+00,  1.8877e+00,\n",
      "         5.7769e-01,  1.7335e-01,  9.4893e-01, -8.0162e-01, -2.6000e+00,\n",
      "        -1.0222e+00,  3.4888e-02, -9.9854e-01, -8.1968e-02, -6.3671e-01,\n",
      "        -4.5430e-01,  3.8848e-01,  9.7832e-01,  2.7443e-01,  9.4557e-01,\n",
      "         3.5290e-01, -8.4722e-01,  1.5983e+00,  7.1790e-01,  6.9795e-01,\n",
      "         3.0778e-01, -4.1127e-01, -7.6690e-01, -6.7735e-01,  1.5611e+00,\n",
      "         4.1434e-01,  1.0285e-01, -5.9417e-01,  5.8629e-01, -4.6453e-01,\n",
      "        -6.8040e-02,  1.2208e+00,  5.6557e-01, -4.0107e-01, -5.2287e-01,\n",
      "         4.3659e-01, -1.9021e+00,  1.1210e+00, -9.7563e-01, -4.3742e-01,\n",
      "         4.4070e-01,  5.1471e-01, -1.6602e-01, -2.1829e-01, -1.4360e+00,\n",
      "        -1.6117e-02,  1.3840e+00, -9.4698e-01, -3.0164e-01, -8.5445e-01,\n",
      "         3.1665e-01,  9.5083e-01, -2.5257e-01, -7.5534e-01,  7.6543e-01,\n",
      "         1.4212e-01,  4.5008e-01,  1.1428e+00, -2.0410e+00, -6.9278e-02,\n",
      "        -2.2260e-02,  1.7524e+00,  2.9635e-01,  2.1899e+00, -1.5958e-01,\n",
      "         1.2764e+00,  1.5196e-01,  8.3260e-01, -1.8426e+00, -1.6472e-01,\n",
      "        -5.8329e-01, -2.4611e-01, -8.7321e-01,  3.0347e-01,  1.1379e+00,\n",
      "        -4.4324e-01, -3.1129e-01, -7.4089e-01, -5.7537e-01, -9.3597e-01,\n",
      "         1.6280e+00,  1.2138e+00, -4.9661e-01,  1.9922e-01,  2.0593e+00,\n",
      "        -2.3735e+00, -5.9293e-01, -9.4991e-01, -1.3756e+00, -9.7152e-01,\n",
      "        -1.5615e-01,  5.1451e-01,  2.4522e+00,  6.5672e-01,  1.8719e+00,\n",
      "        -1.0295e+00,  2.7181e+00, -1.9044e-01,  1.4333e+00, -1.1733e+00,\n",
      "        -1.8443e+00, -1.8970e+00, -1.9323e+00,  4.3340e-01,  9.1546e-01,\n",
      "        -3.0823e-01,  1.0949e+00,  1.5415e+00,  9.2085e-01, -3.5270e+00,\n",
      "        -7.5485e-01,  3.3690e-01, -9.0544e-02, -6.8760e-02,  6.6953e-02,\n",
      "        -7.9537e-01,  6.5000e-01,  2.6316e-02, -1.6040e-01,  1.1999e+00,\n",
      "         6.0687e-02,  9.1188e-01,  1.2611e+00,  1.4574e+00, -6.8548e-01,\n",
      "         9.9961e-01, -1.8483e+00, -1.6026e+00, -1.3871e+00, -6.2812e-02,\n",
      "        -3.2275e-01,  2.8933e-01, -4.2354e-01, -8.5518e-01, -1.0258e+00,\n",
      "        -1.5700e+00,  3.0156e-01,  5.0408e-01,  1.0819e-01, -9.6328e-01,\n",
      "        -2.7030e-01, -7.9450e-01,  1.5716e+00,  1.7316e+00, -1.6532e-01,\n",
      "         2.4588e-02,  1.3538e-01, -1.7845e+00, -1.8450e+00,  1.3966e+00,\n",
      "        -2.1342e-01,  7.9236e-01, -5.1406e-01, -3.0141e-01, -8.9170e-01,\n",
      "         1.3979e+00, -4.1522e-01, -6.9165e-01,  1.9936e+00, -7.4783e-01,\n",
      "        -5.2626e-01, -1.6740e+00,  7.2058e-01, -1.5497e+00,  1.6892e+00,\n",
      "         2.7073e-01,  1.6312e-01, -3.4928e-01,  4.1475e-01,  2.3896e+00,\n",
      "        -6.5151e-01,  6.3607e-01,  6.6964e-01, -1.0497e+00,  5.5830e-01,\n",
      "         2.7010e-01,  7.4410e-01, -5.9796e-01,  1.6733e+00,  1.5166e+00,\n",
      "        -2.1001e-01,  1.6823e+00,  1.8792e+00,  7.2604e-01, -1.2704e-01,\n",
      "         2.1422e-01, -1.1943e-02,  5.3071e-01, -1.0353e+00,  2.3346e-01,\n",
      "        -4.2332e-01, -8.5348e-01, -1.8510e-01,  1.2584e+00, -3.5428e-01,\n",
      "         4.6395e-01,  4.9371e-01, -7.1883e-01,  9.7945e-01,  1.3225e+00,\n",
      "         4.2920e-01, -3.5177e-01, -9.4269e-01, -4.2473e-02, -6.5587e-01,\n",
      "        -2.2888e-01, -1.0200e+00,  7.5681e-02,  9.9582e-01, -2.4592e-01,\n",
      "         2.3644e+00,  1.1846e+00, -7.7036e-01, -4.3424e-01],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "first_channel_first_batch = embeddings[0, 0, :]\n",
    "\n",
    "# Print the result\n",
    "print(first_channel_first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c8602",
   "metadata": {},
   "source": [
    "These dimensions should now be ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
