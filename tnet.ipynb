{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23da015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Folder names\n",
    "folder_path = \"small_dataset/train\"  \n",
    "file_name = \"f_0.json\"        \n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215569b1",
   "metadata": {},
   "source": [
    "Peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637d50dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula\n",
      "formula_depth\n",
      "points\n",
      "n_vars\n",
      "n_consts\n",
      "n_points\n",
      "var_bound_dict\n",
      "const_value_dict\n",
      "meta_list\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{file_name} doesn't exist at {folder_path}.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Couldn't decode {file_name}.\")\n",
    "\n",
    "for key, value in data.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b27b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_0': [-2.79008, -1.43651, -1.39172, 0.24824, 3.63193, -1.02878, -3.51268, 0.03997, -4.64088, -1.57417, 0.13335, 0.17542, 3.20014, 3.0211, -2.15762, -1.9855, 4.81394, -1.10188, -3.58234, 1.55946, -2.54935, 1.04478, 3.21744, -3.25277, -0.4874, -1.18187, 4.95992, 2.10747, -4.20734, -2.70941, -3.44772, -4.85176, -1.84627, -1.79998, -2.6889, 0.54344, -2.81412, 4.43828, 2.33473, -3.79659, -2.3523, 4.84024, -2.96959, -3.87053, -2.67405, 2.13423, 0.13502, -4.34976, -1.37471, -4.10443, -2.09117, -3.2892, -2.79626, 2.79426, 2.82545, 2.32883, 1.91456, -2.57005, -0.5899, -0.40422, 0.34098, 3.55448, 3.88414, -2.8427, -0.69123, -3.50898, 1.47471, 0.70889, 3.49245, 0.20351, 2.78136, -1.81472, 1.95154, -4.64605, -3.50091, -0.5112, 3.90975, 3.83586, 0.96975, -3.71553, 1.82143, -3.2294, -1.49144, -1.84215, 3.87718, 1.89716, -4.27646, 3.45696, -0.68395, 2.54025, 2.79105, 4.97805, -1.52602, 3.62118, -2.13553, 4.98068, -0.87596, 1.61298, 4.99432, -2.97843], 'var_1': [1.23101, 4.99008, 4.44332, -2.80567, -4.01179, -0.73612, 2.65338, 2.92275, 1.04908, 1.15769, -3.78815, -0.56448, 0.74989, 1.83006, -4.07685, 1.91262, 4.427, 2.88422, 1.23448, -4.04655, 2.92468, 1.6573, 0.46726, 3.04141, 1.70319, -0.29049, -2.65644, 0.05933, -3.46396, -4.40029, -2.65628, -1.3515, 1.47093, -0.00498, 2.38474, 2.39259, 2.07677, 0.47953, 1.64698, 4.74239, 2.07602, 2.40869, -2.11347, -0.22244, -0.63653, -1.41104, -0.44487, 0.96848, 1.24463, 3.38442, 1.61505, 3.70423, 1.56227, -1.5241, 1.29663, 2.30483, 1.84468, 3.51294, 4.06664, -1.64065, -4.19919, 1.57952, -3.89914, 3.835, 3.2193, 2.10721, 4.28667, 3.84101, 4.19202, 2.38992, -1.29509, -4.52511, -4.35436, 2.92183, -3.06449, -1.87507, 0.87204, -3.6881, 4.82185, 3.15783, 0.83952, 4.08987, -0.06376, 3.93496, 3.24335, -4.8337, 2.96148, 2.81155, -1.80572, -0.07374, -3.59998, 1.65189, 1.72753, 4.79682, 2.23003, -0.48583, -3.20571, 2.88117, -1.42083, 4.43825], 'var_2': [-2.25072, -3.03545, 1.20933, 4.1356, -3.59812, -4.60251, 4.71545, -3.65898, 1.06284, -3.03963, -3.33861, -3.44461, 2.11222, 2.61192, -3.8118, -3.62642, 4.30206, 0.89286, 2.80203, -4.19825, -4.45426, -1.04361, 0.56589, -1.31317, 2.13749, 1.7284, -0.5393, -4.22764, 0.97047, -2.56715, -1.13147, -4.89665, 0.1978, 1.97428, 0.77103, 2.49323, 5.00671, 1.33296, -2.74807, 0.735, -2.56588, -1.711, -1.45604, 0.15823, 0.21349, 1.68354, -0.6084, -3.12458, -0.0967, 2.95444, 2.01413, -3.85156, 4.52002, -1.99025, 0.84468, -4.64498, 4.11393, 1.8084, -2.24341, 1.84908, -2.0538, -2.42241, -0.54433, 0.98053, -2.91173, 2.43821, 0.80562, -4.9532, 0.51399, -0.7872, 1.68877, 4.02645, -2.33953, 1.70043, -3.44886, -4.14377, 4.29138, 3.64793, 0.0401, -3.61518, -2.35786, 0.67641, 1.51657, 1.93891, 2.47306, -2.87433, -2.02626, -4.89856, -4.26307, -1.906, -3.15319, -0.084, 3.49988, 2.24713, 2.55848, 1.00587, 1.99668, -3.20733, 0.52969, 0.72002], 'target': [8.83213, 1000000.01962, -83149.46566, 183.28609, -24623.24181, 5.66045, 10.69599, 211.93865, 5.54178, 7.35384, 3857.25162, 3.58247, 5.51044, 23.313, 17876.98023, 26.63496, 110742.02319, -245.394, -1.42164, 8042.42841, 372.50016, -51.78898, 3.72782, 364.48935, 5.87409, -1.69288, 127.0085, 1.89776, 1158.07428, 55560.45862, 131.07503, 13.76693, 3.63158, -3.62779, 24.99926, 46.86327, 16.25031, 4.97672, -7.23973, 1000000.02949, 32.90957, 54.02126, 33.17873, 3.34915, 2.67692, 9.82365, -2.23413, 8.14795, 2.05087, 125.05429, -23.31184, 4570.50766, 4.46216, -1.39028, 7.70854, 29.52739, 25.12372, -385.05655, 9463.81837, 3.49568, 9096.28517, 1.2109, 6053.96732, 2436.41594, 575.27706, 2.18503, 16327.40669, 6528.19337, 27735.95762, -20.34707, 9.0649, 76952.05457, -28056.38589, 193.60638, 569.17746, 22.20415, 7.58246, 4571.45493, 1749.999, 762.55443, -2.11144, 9389.88781, -9.5185, -20250.49088, 936.12451, -35009.93803, 377.95491, 51.46854, 21.23147, -1.13412, -1718.63293, 16.03416, 7.76994, 999999.99803, -26.44775, 5.20704, 42.34638, 73.73413, 12.29975, 41425.48377]}\n"
     ]
    }
   ],
   "source": [
    "print(data['points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc1329",
   "metadata": {},
   "source": [
    "Read the files f_0.json, f_1.json, etc. Create a pytorch tensor with batch size num_files containing each equation's set of points. Each set of input points is represented by a 100 x 4 matrix [x_0 x_1 x_2 y], where x_0 is an array of 100 values and similarly for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30493ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Number of json files to read\n",
    "num_files = 16\n",
    "\n",
    "for i in range(num_files):\n",
    "    folder_path = \"small_dataset/train\"\n",
    "    file_name = f\"f_{i}.json\"\n",
    "\n",
    "    # File path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_name} doesn't exist at {folder_path}.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Couldn't decode {file_name}.\")\n",
    "        \n",
    "    point_data = [data['points']['var_0'], data['points']['var_1'], data['points']['var_2'], data['points']['target']]\n",
    "    \n",
    "    input_data = {\n",
    "        \"pointwise_data\": point_data\n",
    "    }\n",
    "    \n",
    "    if i == 0:\n",
    "        train_points = torch.tensor(input_data['pointwise_data'], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        points = torch.tensor(input_data['pointwise_data'], dtype=torch.float32).unsqueeze(0)\n",
    "        train_points = torch.cat((train_points, points), dim=0)\n",
    "\n",
    "print(train_points.shape) # [batch size, channels, sequence length]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf57ba5",
   "metadata": {},
   "source": [
    "This is the implementation from SymbolicGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16fd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVars = 3 # number of x variables\n",
    "numYs = 1 # number of y variables\n",
    "embeddingSize = 512\n",
    "num_units = embeddingSize\n",
    "\n",
    "# Define the embedding model\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        \n",
    "        self.activation_func = F.relu\n",
    "        self.num_units = embeddingSize\n",
    "\n",
    "        self.conv1 = nn.Conv1d(numVars + numYs, num_units, 1)\n",
    "        self.conv2 = nn.Conv1d(num_units, 2 * num_units, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * num_units, 4 * num_units, 1)\n",
    "        self.fc1 = nn.Linear(4 * num_units, 2 * num_units)\n",
    "        self.fc2 = nn.Linear(2 * num_units, num_units)\n",
    "\n",
    "        self.input_batch_norm = nn.BatchNorm1d(numVars + numYs)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_units)\n",
    "        self.bn2 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn3 = nn.BatchNorm1d(4 * self.num_units)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn5 = nn.BatchNorm1d(self.num_units)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_batch_norm(x)\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        print(x.shape)\n",
    "        x, _ = torch.max(x, dim=2)  \n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        print(x.shape)\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7588720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 100])\n",
      "torch.Size([16, 512, 100])\n",
      "torch.Size([16, 1024, 100])\n",
      "torch.Size([16, 2048, 100])\n",
      "torch.Size([16, 2048])\n",
      "torch.Size([16, 1024])\n",
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = EmbeddingModel()\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model(train_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322b657",
   "metadata": {},
   "source": [
    "The output is a vector of size 1 x e, where e is the embedding size. In this example, we use e = 512. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
